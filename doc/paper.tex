% notes

\documentclass[format=sigconf, review=true, draft=true, screen=true]{acmart}
% \documentclass[sigplan,authorversion,draft]{acmart}

% don't print the conference ref for now
% \settopmatter{printacmref=false}

\usepackage{comment}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphics,graphicx}
\usepackage{pstricks,pst-node,pst-tree}
\usepackage{auto-pst-pdf}

% from matias
\usepackage{balance}

\usepackage{listings}
\lstset{
language=bash,
% backgroundcolor=\color[rgb]{0.95, 0.95, 0.95},
tabsize=2,
rulecolor=,
basicstyle=\ttfamily,
upquote=true,
% aboveskip={1.5\baselineskip},
columns=fullflexible,
% columns=fixed,
showstringspaces=false,
extendedchars=true,
breaklines=true,
prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
frame=L,
showtabs=false,
showspaces=false,
showstringspaces=false,
% identifierstyle=\ttfamily,
keywordstyle=\color[rgb]{1.0,0,0}\bfseries,
keywordstyle=[1]\color[rgb]{0,0,0.75}\bfseries,
keywordstyle=[2]\color[rgb]{0.5,0.0,0.0},
keywordstyle=[3]\color[rgb]{0.127,0.427,0.514},
keywordstyle=[4]\color[rgb]{0.4,0.4,0.4},
commentstyle=\color[rgb]{0.5,0.5,0.5}\itshape,
stringstyle=\color[rgb]{0.639,0.082,0.082},
morekeywords={read-lines, take, each},
deletekeywords={do, read},
%numbers=left,%
numbersep=5pt,%
numberstyle=\tiny\color{gray},%
emphstyle=\bfseries,%
breaklines=true,
breakatwhitespace=true,%
escapechar=`,
%numbers=left,
}
\lstset{escapeinside={<@}{@>}}
\definecolor{ttblue}{rgb}{0,0,0.75}
\title{A Shell-like Model for General Purpose Programming}
\author{Jeanine Adkisson}
\affiliation{\institution{Tokyo Institute of Technology}}
\email{jneen@prg.is.titech.ac.jp}

\author{Johannes Westlund}
\affiliation{\institution{TODO}}
\email{TODO}
\begin{document}

\author{Hidehiko Masuhara}
\affiliation{\institution{Tokyo Institute of Technology}}
\email{masuhara@prg.is.titech.ac.jp}

% thought experiment - parallel fetching
% find an example of named pipes

% TODO LIST
% * Find an example of named pipes reopening
% * Find an example of a non-linear pipe arrangement (prob. from flow-based programming)
% * Plan the Description of Magritte section
% * Add Call Semantics to Design Considerations
% * Institute and email addr from Johannes
% * Explain why we do not do eager interruption (limit sources of interruptions)
% * Finish Non-Interruption section
% * Completely redo the Magritte section
% * Bibliography
% * Pretty Syntax

\begin{abstract}
Shell languages such as bash are designed to integrate with an OS, which mainly involves managing processes with implicit input and output streams. They also attempt to do this in a compact way that could be reasonably typed on a command-line interface.

However, existing shell languages are not sufficient to serve as general-purpose languages - values are not observable except in raw streams of bytes, and they lack modern language features such as lexical scope and higher-order functions.

By way of a new programming language, \emph{Magritte}, we propose a general-purpose programming language with semantics similar to bash. In this paper, we discuss the early design of such a system, in which the primary unit of composition, like bash, is processes with asynchronous inputs and outputs, which can be read from or written to at any time, and which can be chained together via a pipe operator. We also explore concurrency semantics for such a language.

% We explore the implementation and design challenges that come with such a model, and also show that this model is able to easily create and compose concurrent algorithms.
% The UNIX shell programming model has been shown to be a successful model for composing programs - spawning unrelated programs in parallel to communicate over operating-system pipes.

% Beyond the most simple tasks, however, \texttt{bash} and similar tools break down, due to the byte-based nature of the system: variables can only hold byte arrays, and pipes can only manage raw byte streams, with no support for transactional writes.
% %
% We explore a pipe-based programming model that attempts to synthesize the good parts of UNIX shells, departing at key points, along with a supporting concurrency model and a semantic of interruption.
%
%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Functional and object-oriented programming suffer from a disconnect between the concept of \emph{functions} and \emph{programs}.  Whereas functions and methods receive values as arguments and return single values as a result, programs can receive data not only as arguments but also asynchronously through an input, and write results asynchronously to an output.
%
% In functional and object-oriented languages, this can result in not only a significant amount of abstraction overhead for dealing with external functions, but the immediacy of function arguments and return values can make composing concurrent programs difficult.
%
% By way of a new programming language, \emph{Magritte}, we propose a programming model in which the primary unit of composition is not immediate function arguments and return values, but instead processes with asynchronous inputs and outputs, which can be read from or written to at any time, and which can be chained together via a pipe operator, much like programs in a UNIX environment. We also explore a concurrency semantic for such a language.
%
% We explore many implementation and programming challenges that come with such a model, and also show that this model is able to easily create and compose concurrent algorithms that would be difficult to write or compose in a functional or object-oriented language.


% Despite the widespread use of GUI tools for configuration and orchestration tasks, CLI tools, and more specifically shell-based interfaces remain a powerful standard for software distribution and integration. Several attempts have been made at solving the desktop-integration problem: how should we allow programs written in different languages and on different platforms to be scripted and integrated in a coherent system? The most notable attempts at this problem have been TCL(TODO: cite!) and Guile Scheme(TODO: cite!), but neither has been as succesful as they intended to be: the common language for a large portion of tools remains shell-based, relying on such concepts as standard I/O, string-based argument vectors, and the expectation that users will be able to freely pipe streams of bytes in a pipe-based way.
%
% Unfortunately, existing UNIX shell languages have significant known interoperability issues, such as lack of any kind of usable encapsulation, and the lack of in-language data structures to represent any kind of value other than a string. We believe that a shell-compatible language with well-defined semantics that could also function as a general-purpose systems language could go a long way towards solving the desktop-integration problem.
%
% On the other hand, a persistent problem with more established systems like Erlang or Go is that they don't account for closing channels, and require manual cleanup of processes. In a systems programming context, errors and hangups are commonplace and expected, and it is critical to have some measure of automatic process cleanup for even naively-written code.
%
% We propose a channel-based communication system that integrates with a workflow compensation system and is capable of recovering from errors and, importantly, cleaning up processes when communication halts.
\end{abstract}
\maketitle

\section{Motivation}

The UNIX shell programming model has been shown to be a successful model for composing programs - spawning unrelated programs in parallel to communicate over operating-system pipes. Beyond the most simple tasks, however, \verb/bash/ and similar tools break down, due to the byte-based nature of the system: variables can only hold byte arrays, and pipes can only manage raw byte streams, with no support for transactional writes.

In this paper, we use the term \emph{pipe-based language} to mean a programming language intended to be used on a command line, with the ability to spawn many processes in which communicate through synchronous channels or pipes in an ad-hoc manner --- and in which this facility is the primary method of composing different functions or units.

% TODO: discuss this
%# fn pipe(lhs, rhs, inp, out) {
%#   c = channel()
%#   go fn () { lhs(inp, c); };
%#   rhs(c, out)
%# }
%#
%# collect = collector()
%# pipe_collect(curry(range, 10), curry(fan, 2,
%  fn(el, inp, out) { write(el + 1, out); }
%), inp);
%#

Our overarching goal is to create a language and a programming system that retains the pipe-based programming and interaction model of bash, but allows for large programs in a way that existing shell languages do not.

\section{Design Considerations}
In this section we discuss several feature requirements and design considerations for a pipe-based language to be viable for large programs.

\paragraph{Not Everything Is a String.}
The first core issue that prevents most shells from being viable for large programs is that only strings are allowed as first-class values.

Several projects\cite{haahr}\cite{duff}, including bash itself, have attempted to add lists and hash-maps as standard objects. Unfortunately, while they allow these values to be stored in variables, most projects do not allow these data structures to be passed into or returned from functions, or importantly, passed through pipes normally.
Since values in these languages cannot be passed through pipes, they are relegated to a second class of value, one for which pipe-based composition is not available.

Thus if we are to allow for pipe-based composition to be the core composition method for large programs, we must allow rich values to be passed through channels.

\paragraph{Transactional Channels.}
Since UNIX pipes can only manage bytes, usually channels with a fixed buffer are specified for performance reasons. However, in the languages we consider, we assume we can transactionally write a single complex value to a channel, resulting in the ability to send data in batch without resorting to a queue that may interleave writes.

Consider the fairly common architecture of producer/consumer: A \emph{producer} process producese values that are processed in parallel by multiple \emph{consumer} processes, and then the values are collected in a single output. This might be expressed in bash as:

\begin{lstlisting}
# pass through the stream, labeling every line
label() {
  while read line; do echo "$1$line"; done
}

# process the stream with different labels
split() {
  label a &
  label b &
}

# process the numbers 1-100, limiting the
# output to the first 3 lines
seq 100 | split | head -3
\end{lstlisting}

Unfortunately, when we run this process, the outputs from the \verb/label/ function become interleaved, resulting in outputs such as:

\begin{verbatim}
a1    b12   a
a2    a     b12
a3    a4    a34
\end{verbatim}
In a language intended for large programs, therefore, writes to a channel must be \emph{transactional} - a single write must be sent wholesale to a single reader without any interleaving, no matter how big the write.

Luckily, given the decision to allow rich values to be passed through channels, a buffer is not as necessary for performance purposes, since a single write may contain an arbitrarily large amount of data - or for that matter a pointer.

\paragraph{Interruption.}
A core requirement of pipe-based languages is a semantic of process \emph{interruption}: automatic clean-up of processes that will no longer be used. Consider the following Magritte code:

\begin{lstlisting}
  read-lines tmp/large-file
    | take 10
    | each (?line => do-expensive-work <@\$@>line)
\end{lstlisting}

In this example, three processes are spawned: (1) a process with a file open that writes one line at a time to its output, (2) a process that reads 10 times from its input, writes each entry to the output, and then exits, and (3) a process that reads every input and calls a function to perform an expensive task.
A user's intent when typing such code may be to read 10 lines from a file and synchronously perform an action on each line.

In a pipe-based language, we expect all three to be running concurrently, communicating through anonymous pipes or channels.
A user will also expect that, after the first 10 lines are processed, the file is closed, and that all three processes exit.
This expectation is despite the fact that process (1) is specified to read the entire file, and process (3) is a theoretically infinite loop.

In a naive implementation using synchronous channels, process (1) will never be able to write more than 10 lines, and will remain blocked on its output with the file open forever.
Similarly, the \verb/each/ function will never be notified that its input has finished, and will block forever on its input stream.

\paragraph{Compensation.} In order to observe interruption, user code must be able to react to and handle interruption. The most direct way to observe interruption is through a system of \emph{compensation actions}, which are expressions which will be evaluated in the case of an interruption.

For example, the function \verb/file-lines/ above could be implemented as:

\begin{lstlisting}
(file-lines ?fname) = (
  handle = (open-file $fname) %%! close-file $fname
  until (=> eof? $handle) (=> read-until "\n" $handle)
)
\end{lstlisting}

In this code, the \verb/%%!/ symbol registers a compensation action that will be run either at the next checkpoint (the end of the function), or when the process is interrupted. In this way, we can ensure that the file is closed when the process exits. Compensations are the only way in which interruptions can be directly observed by client code - without compensations, the only way of observing forever-blocked processes would be to inspect the process table, or observe the memory footprint of the program. Thus, we can define the primary task of our system as \emph{running a process's compensation actions at the appropriate time}.

\paragraph{Interrupting on Operations vs. Eager Interruption.}

In designing an interruption semantic, we must first decide whether processes are eagerly interrupted when their channels close, or only interrupted on channel operations.

Consider the following example, with the assumption that \\ \verb/do-other-operation/ does not write to the standard output:

\begin{verbatim}
count-forever | ( take 5; do-other-operation ) | take 5
\end{verbatim}

The middle process will write five times, and then continue to do other processing in-thread that does not write to the standard output.
The final \verb/take 5/ operation will return after 5 inputs are read.
It is important to decide, then, whether the middle process should be \emph{interrupted} in the middle of \verb/do-other-operation/, or should it be left alone?

An advantage of lazy interruption is that a user can identify precisely which points in the code have the potential to be interrupted - those points which run a \verb/put/ or a \verb/get/. Whereas with eager-interruption semantics any point in the code may be interrupted, introducing the need for users to either mark critical uninterruptible sections or be very careful about setting correct compensations in the case of mutative algorithms.

On the other hand, lazy interruption has the disadvantage that a producing process must do enough work to produce one more value than will be consumed. If each value is relatively cheap to produce, this is not a problem, but in the case that the values are expensive to produce, this would result in doing a large amount of unnecessary work.

Overall, we have decided that the predictability of lazy interruption is worth the tradeoff for extra values, and we discuss some features that may mitigate this problem in \emph{Future Work}.

\paragraph{Non-closing of Channels.}

Given that multiple processes may be reading from and writing to a channel, it is often the case that a communicating process will end when there are other processes still communicating over the channel. It would not be appropriate in this case to interrupt other processes attached to the channel, as they are still able to communicate.

We define our guiding principle for the appropriate time to interrupt a process as: \emph{A process is interrupted exactly when it can no longer be woken up}.
When a process is blocked on a synchronous channel, it will be woken up as soon as another process communicates on the other end.
Therefore the appropriate time for it to be interrupted is if it is blocked on a channel that will never receive any more operations.
In traditional channel-based systems, this is difficult to detect, because a reference to a channel could be passed anywhere in the program as a standard value, and be interacted with in any way at any time.

Luckily, in pipe-based languages, the arrangement of pipes is usually specified at process spawn time. This enables us to maintain a process register inside of each channel, so that we can decide when all readers or all writers have detached from a channel, at which time the channel closes and interrupts all blocked processes.

\paragraph{Closing Permanence.}
Though we close a channel when all processes on the read or write sides close, there is always the possibility of new processes spawning and attempting to connect to a channel. In such a case, some systems leave open the possibility of \emph{reopening} a channel for further use. In UNIX, for example, the named-pipes API allows for persistent channels (TODO: cite!) that, being merely files, can be reopened at any time.

However, this can lead to some unexpected races between a channel closing and a new process spawning. Consider the example:

\begin{lstlisting}
c = (make-channel)
& count-forever > $c
& take 10 < $c
put 10 > $c
\end{lstlisting}

This example, while contrived, represents an unavoidable race with first-class channels - whether the process running \verb/take 10/ closes the channel before or
after the \verb/put 10/ invocation opens the channel for writing. If we allow channel reopening, we will either block forever, or insert the number 10 into the stream, depending on which happens first. However if we do not allow channel reopening, we can say that, if a process initiates a read or write on a closed channel, it is immediately interrupted. In this case, both sides of the former race have the same termination behavior - the process is closed when \verb/take 10/ returns.

\paragraph{Masking Interruptions.}

A user will often wish to continue after a particular output channel has closed, and in this case will need a facility to mask exceptions for particular channels. Consider the following example, which uses reservoir-sampling to select a uniform random element from a stream:

\begin{lstlisting}
(sample) = (
  hold = (get)
  i = 1
  each (?v =>
    $i = (inc $i)
    # mutate the $hold variable with probability 1/$i
    prob $i 1 && ($hold = %v)
  )

  put $hold
)
\end{lstlisting}

In this example, the function \verb/each/ will consume the entire input stream and mutate a variable with a given probability. After the entire input stream is consumed, we wish to output the resulting value stored in the \verb/$hold/ variable.

However, with the semantics described above, the \verb/each/ function will loop until it is given an interrupt signal from the input channel closing, which will interrupt the entire process and not continue to the following line. In order to avoid this situation, the \verb/each/ function must somehow indicate that it intends to consume the entire stream, and handle the interrupt signal.

While we plan to explore more general mechanisms for error handling, for cases such as this it suffices to provide two builtins, \verb/produce/ and \verb/consume/, each of which takes a single function to loop forever until the standard output or standard input respectively is consumed, whereby control flow continues after the invocation. Using these functions, we might define \verb/each/ as:

\begin{lstlisting}
(each ?fn) = (consume (=> %fn (get)))
\end{lstlisting}

With this definition, the call to \verb/consume/ will mask the interruption, and control flow within the \verb/sample/ function will proceed as normal.

\section{Description of Magritte.}

(TODO: \verb/{add,remove}_{reader,writer}/ are hidden intrinsics, only called automatically at process spawn and exit (even for exits that are in error). and we only allow reads/writes for processes *attached* to channels, rather than freely through channel variables. explain this)

We extend the notion of a synchronous channel with \emph{registered readers} and \emph{registered writers}, and add four intrinsic functions: \verb/add_reader/, \verb/remove_reader/, \verb/add_writer/, and \verb/remove_writer/, each receiving a channel and a process handle.
These store and delete processes from the channel's internal sets of registered readers and registered writers.

In this way, we can know relatively certainly when a channel will never unblock - if either the read or the write end has no remaining processes holding it open, we immediately close it. While it is still possible for processes to attempt to attach new processes to a closed channel

Additionally, \verb/remove_reader/ and \verb/remove_writer/ will cause the channel to close if their corresponding sets are empty after the operation.

When a channel is closed, we first interrupt every process that is blocked on the channel.
Thereafter, any attempted read or write operations will cause the initiating process to be interrupted.
When a channel is interrupted, we must not only perform any cleanup actions such as closing files or writing to error logs, but also call \verb/remove_reader/ and \verb/remove_writer/ on any channels the process has registered - thereby potentially cascading the interruptions to other processes.


\section{Magritte}

We have implemented \verb/magritte/(TODO: cite), a Ruby DSL that allows communication between native Ruby threads, and automatically cleans up dangling threads with the above semantics.
The API revolves around a \verb/Magritte::Code/ object, which can also be created with the builtin \verb/s/ primitive.

Within a code object, the primitive functions \verb/put/ and \verb/get/ can be used to read from the input and write to the output.
A code object can be run in-process (\verb/.call/), in the background (\verb/.go/).
The default output is a special kind of write-only channel called a \verb/Collector/, which never blocks, but collects every written value into an array.

Input and output channels can be set \emph{outside} of a channel using the \verb/.from(channel)/ and \verb/.to(channel)/ methods.
However, they are by default inherited from the enclosing context, meaning that it is straightforward to spawn multiple concurrent processes that are attached to the same channels.

Consider the example:

\begin{verbatim}
s { i = 0; loop { put i; i += 1 } }
  .p { s { drain }.go; s { drain }.go }
  .p { take 10 }.call
\end{verbatim}
In this example, we spawn four processes.
The first line spawns an infinite loop that generates all positive integers.
The second line spawns two processes, both reading from the same input and writing to the same output.
Finally the third line spawns a process that reads and writes 10 values, then returns. The definition of \verb/drain/ is very simply:

\begin{verbatim}
def drain
  loop { put(get) }
end
\end{verbatim}
so that it completely drains the input channel into the output.
But since there are two of these processes running concurrently, races are possible.

According to the semantics described above, both draining processes will be cleaned up when \verb/take 10/ returns, causing the generation loop to also be closed.
Notably, even though the second process in the pipeline, which spawns the two \verb/drain/ processes, will exit immediately after spawning, this won't result in any programs closing, since the two consumer processes are also registered as readers and writers to the standard input and standard output of the middle process.


% \verb{...} inline \verbatim
% \verb+abc_def+

% example of bash race conditions based on re-opening channels

\section{Related Work}

PEP 533 Authors(TODO: cite properly) describe an automatic closing system for generators, in which an \verb/__iterclose__/ signal is sent by the consumer back to the producer as soon as a consumer exits early.
But channel-based systems generally allow for multiple concurrent readers and writers - so automatically cleaning up a channel when a single consumer exits would cause processes that are still able to communicate to be terminated early.
We propose a system such that processes are interrupted as soon as it is no longer possible for them to resume.

The Bourne Again Shell (\"bash\")

Python PEP 533; Go, Erlang; Guile Scheme, TCL;

The \verb/rc/ shell \cite{duff} from the Plan 9 operating system from Bell Labs introduces a list data type to shell, and cleans up some of the historical surprising quotation behavior of bash. However its list type is not nestable - nested lists are automatically flattened at creation time. Additionally, these lists cannot be passed through channels.

The \verb/es/ shell \cite{haahr} attempts to extend the standard shell model with lambda functions with lexical scoping. These shell functions are marshalled into strings when passed through pipes (whether to shell functions or external programs), but are still written byte-by-byte and thus are subject to interleaving in concurrent cases.


\bibliographystyle{ACM-Reference-Format}
\bibliography{paper}

\end{document}

