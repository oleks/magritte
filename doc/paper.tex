% default is sigpro, define \sigplan to switch

\ifx\sigplan\undefined
\newcommand{\ifsigplan}[1]{}
\newcommand{\ifsigpro}[1]{#1}
\else
\newcommand{\ifsigplan}[1]{#1}
\newcommand{\ifsigpro}[1]{}
\fi

\ifsigpro{ \documentclass[english,PRO]{ipsj} }
\ifsigplan{ \documentclass[sigplan,9pt]{acmart} }

% \usepackage[utf8]{inputenc}

\usepackage{textcomp}
\usepackage{comment}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphics,graphicx}
\usepackage{pstricks,pst-node,pst-tree}
\usepackage{auto-pst-pdf}
% \usepackage[symbol]{footmisc}

% from matias
\usepackage{balance}

\usepackage{listings}
\lstset{
language=ruby,
% backgroundcolor=\color[rgb]{0.95, 0.95, 0.95},
tabsize=2,
rulecolor=,
basicstyle=\ttfamily,
upquote=true,
% aboveskip={1.5\baselineskip},
columns=fullflexible,
% columns=fixed,
showstringspaces=false,
extendedchars=true,
breaklines=true,
prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
frame=shadowbox,
showtabs=false,
showspaces=false,
showstringspaces=false,
% identifierstyle=\ttfamily,
keywordstyle=\color[rgb]{1.0,0,0}\bfseries,
keywordstyle=[1]\color[rgb]{0,0,0.75}\bfseries,
keywordstyle=[2]\color[rgb]{0.5,0.0,0.0},
keywordstyle=[3]\color[rgb]{0.127,0.427,0.514},
keywordstyle=[4]\color[rgb]{0.4,0.4,0.4},
commentstyle=\color[rgb]{0.5,0.5,0.5}\itshape,
stringstyle=\color[rgb]{0.639,0.082,0.082},
morekeywords={read-lines, take, each, produce, consume, put, get, make-channel},
deletekeywords={do, read},
%numbers=left,%
numbersep=5pt,%
numberstyle=\tiny\color{gray},%
emphstyle=\bfseries,%
breaklines=true,
breakatwhitespace=true,%
escapechar=`,
%numbers=left,
}
\lstset{escapeinside={<@}{@>}}
\definecolor{ttblue}{rgb}{0,0,0.75}

\usepackage[varg]{txfonts}%%!!
\makeatletter%
\input{ot1txtt.fd}
\makeatother%

\ifsigpro{
\usepackage{PROpresentation}
\PROheadtitle{2018-4-(5): Manuscript for presentation at IPSJ-SIGPRO, 17 Jan 2019.}
}

\ifsigplan{
\acmDOI{}
\copyrightyear{2019}
\acmISBN{}
\acmConference[PASS Workshop]{}{April 2019}{Genova, Italy}
\setcopyright{none}
\titlenote{This work was presented at the 122nd IPSJ SIGPRO workshop on January 17, 2019. The presentation was not refereed, and the same manuscript was distributed only to the participants to the workshop.}
}

\begin{document}

\title{A Shell-like Model for General Purpose Programming}

\ifsigpro{
\affiliate{TITech}{%東京工業大学情報理工学院数理・計算科学系 \\
Department of Mathematical and Computing Science, Tokyo Institute of Technology,
Meguro, Tokyo 152-8552}
\affiliate{KTH}{Kungliga Tekniska H\"ogskolan\\
KTH Royal Institute of Technology, Stockholm, Sweden, 10044}

\author{Jeanine Miller Adkisson}{TITech}[jneen@jneen.net]
\author{Johannes Westlund}{TITech,KTH}[jwestlun@kth.se]
\author{Hidehiko Masuhara}{TITech}[masuhara@acm.org]
}

\ifsigplan{
\author{Jeanine Miller Adkisson}
\affiliation{%
  \institution{Tokyo Institute of Technology, Japan}
}
\email{jneen@jneen.net}

\author{Johannes Westlund}
\affiliation{%
  \institution{Tokyo Institute of Technology, Japan}
}
\affiliation{%
  \institution{KTH Royal Inst. of Technology, Sweden}
}
\email{jwestlun@kth.se}

\author{Hidehiko Masuhara}
\affiliation{
  \institution{Tokyo Institute of Technology, Japan}
}
\email{masuhara@acm.org}
}

% thought experiment---parallel fetching
% find an example of named pipes

% TODO LIST
% x Find an example of named pipes reopening
% * Find an example of a non-linear pipe arrangement (prob. from flow-based programming)
% * Pretty Syntax

\begin{abstract}
Shell scripting languages such as bash are designed to integrate with an OS, which mainly involves managing processes with implicit input and output streams. They also attempt to do this in a compact way that could be reasonably typed on a command-line interface.

However, existing shell languages are not sufficient to serve as general-purpose languages---values are not observable except in raw streams of bytes, and they lack modern language features such as lexical scope and higher-order functions.

By way of a new programming language, \emph{Magritte}, we propose a general-purpose programming language with semantics similar to bash. In this paper, we discuss the early design of such a system, in which the primary unit of composition, like bash, is processes with input and output channels, which can be read from or written to at any time, and which can be chained together via a pipe operator. We also explore concurrency semantics for such a language.
\end{abstract}

\settopmatter{printfolios=true}
\maketitle

\section{Motivation}\label{motivation}

\noindent
The UNIX shell programming model has played an important role in integrating applications and operating systems by composing programs---spawning independent programs in parallel to communicate over operating-system pipes. Beyond the most simple tasks, however, bash and similar tools break down, due to various language deficiencies.

In this paper, we use the term \emph{pipe-based language} to mean a programming language intended to be used on a command line, with the ability to spawn many processes which communicate through synchronous channels or pipes in an ad-hoc manner---and in which this facility is the primary method of composing different functions or units.

Our overarching goal is to create a language and a programming system that retains the pipe-based programming and interaction model of bash, but allows for large programs in a way that existing shell languages do not.

\subsection*{Outline}\noindent
In this work, we present a new pipe-based language \emph{Magritte}. Section 2 describes design requirements for a language in this space. Section 3 and 4 describe Magritte's design and implementation. Section 5 describes our future goals with this project, and in Section 6 we review various related work and alternative approaches.

\section{Design Considerations}\label{design-considerations}\noindent
In this section we discuss several feature requirements and design considerations for a pipe-based language to be viable for large programs.

\subsection{Programming With Values}

\subsubsection{Value Pipes}\noindent
It is desirable in a general purpose language to be able to create and use complex data structures, and to use them freely throughout the language. In particular, if we are to allow for pipe-based composition to be the core composition method for large programs, we must allow rich values to be passed through pipes.

Several projects\cite{haahr,duff}, including bash itself, have attempted to add arrays and associative arrays as standard objects, but not as first class values: they do not allow these data structures to be passed into or returned from functions, or importantly, passed through pipes.
%These values are therefore relegated to a second class of value, one for which pipe-based composition is not possible.

Furthermore, serialization through pipes is generally not possible except in a single-threaded case, since complex data can be corrupted through interleaving.

For example, consider the fairly common architecture of producer/consumer: A \emph{producer} process produces values that are processed in parallel by multiple \emph{consumer} processes, and the values are collected in a single output. This might be expressed in bash as:
\begin{lstlisting}[morekeywords={do,done}]
# <@\underline{\color{gray} consume}@> the stream, labeling every line
label() { while read x; do echo "$1$x"; done ;}

# process the stream with two threads
split() { label a & label b & ;}

# <@\underline{\color{gray} produce}@> and process the numbers 1-100,
# limiting output to the first 3 lines
seq 100 | split | head -3
\end{lstlisting}
With this code, a user might expect the output to be three lines, each consisting of a letter \verb/a/ or \verb/b/, and a number, for example:

% \footnotetext{hello world}

\noindent\begin{minipage}{.14\textwidth}
\begin{lstlisting}{Name}
a1
a2
a3
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.14\textwidth}
\begin{lstlisting}{Name}
b1
a3
b2
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.14\textwidth}
\begin{lstlisting}{Name}
a2
b1
a3
\end{lstlisting}
\end{minipage}

\noindent
Unfortunately, when we run this process, the outputs from the \verb/label/ function become interleaved\footnotemark, resulting in outputs such as:
\footnotetext{We have observed some behavior in the output that cannot be explained simply by interleaving, suggesting there may be some other race conditions in play.}

\noindent\begin{minipage}{.14\textwidth}
\begin{lstlisting}{Name}
a2
b1
b
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.14\textwidth}
\begin{lstlisting}{Name}
b12
a
a4

\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.14\textwidth}
\begin{lstlisting}{Name}
a
b12
a34
\end{lstlisting}
\end{minipage}

\noindent
This behavior is in accordance with the Linux User's Manual \cite{linux-pipe}:
\begin{lstlisting}
The communication channel provided by a pipe is
a <@\emph{byte stream}@>: there is no concept of message
boundaries.
\end{lstlisting}

\noindent
In order to provide a channel implementation that is usable for large programs, we must ensure that it is \emph{consistent}---that is, that every read corresponds to exactly one write. Value pipes accomplish this by making a value the smallest atomic unit of communication.


% cat $(ls | grep ...)
\subsubsection{Capture and Substitution}\label{return-semantics}\noindent
For processes that output values, we need to support a mechanism to capture those values for use in variables, data structures, and function arguments, similar to backticks or \verb/$(...)/ in bash. This enables processes to be used like functions, which return data to their caller.

But since in most shells, rich values are not writable to output streams, the output cannot effectively be used as a return path for values. Es Shell\cite{haahr} accounts for this by introducing a \emph{return value} which is separate from stream output and can be accessed via special-purpose call syntax.

If we allow values to be written to output streams, however, we can directly capture values written to the output.

\subsubsection{Modern Language Features}
%Suggestion: without using subsubsections, list the features as a list (by using the itemize environment). And add first class functions into the list, and a prototype-based lookup mechanism.

Users will expect a modern programming language to have:
%Language features required for a modern general purpose language include:

\begin{itemize}
  \item \emph{Lambda functions with closure}.
    This requires the introduction of lexically scoped variables.
  \item \emph{Dynamic variables}.
     Most shell languages already include these, as OS Environment variables are dynamic by nature.
  \item \emph{Product structures with support for open recursion}.
    a prototype-based object system is sufficient for this.
  \item \emph{Sum structures}. In an untyped language, a method for pattern matching over nestable heterogenous lists is sufficient.
\end{itemize}

% For large programs, an object system is desirable as a way to provide user-defined types and abstractions. The existing foundations of shell languages already make use of the UNIX \emph{environments} API, which consists of a map of strings to strings, together with a parent pointer. Therefore, if we allow environments as first-class values, they can be used in a straightforward manner as prototype-based objects.

% For programs that deal with syntax or other kinds of trees, it is convenient to have compact nestable data structures that support pattern matching, which can be made possible with nestable vectors.

\subsection{Automatic Process Cleanup}
\subsubsection{Interruption}
\noindent
In shell programming, we tend to compose infinitely running processes together as pipeline elements. Thus we require a well-defined semantics of process \emph{interruption}\footnotemark: automatic clean-up of processes that will no longer be used. Consider the following Magritte code:
\footnotetext{We use the term \emph{interruption} in the generic sense---to mean the halting of normal flow in a process, due to some external event. It is unrelated to hardware or OS signalling.}
\begin{lstlisting}
  read-lines tmp/large-file                        <@\color{gray}\hfill $(1)$@>
    | take 10                                      <@\color{gray}\hfill $(2)$@>
    | each (?line => do-expensive-work <@\$@>line) <@\color{gray}\hfill $(3)$@>
\end{lstlisting}

\noindent
In this example, three processes are spawned concurrently: (1) a process with an open file that writes one line at a time to its output, (2) a process that reads 10 times from its input, writes each entry to the output, and then exits, and (3) a process that reads every input and calls a function to perform an expensive task.
A user's intent when typing such code may be to read 10 lines from a file and synchronously perform an action on each line.

A user will also expect that, after the first 10 lines are processed and the \verb/take/ function returns, the file will be closed, and all three processes exit.
This expectation is despite the fact that process (1) is specified to read the entire file, and process (3) is an infinite loop.

In a naive implementation using synchronous channels, process (1) will never be able to write more than 10 lines, and will remain blocked on its output with the file open forever.
Similarly, the call to the \verb/each/ function will never be notified that its input has finished, and will block forever on its input stream.

\subsubsection{Compensation}\noindent
In interacting with an operating system, it is necessary to mange side effects, and gracefully recover or restore state in the case of an interruption. Such an error-handling system would also be a way for user code to directly observe interruption.

Without compensation of errors, the only way of observing forever-blocked processes would be to inspect the process table, or to observe the memory footprint of the program. Thus, we can define the primary task of the interruption system as \emph{running a process's compensation actions at the appropriate time}.

\subsubsection{Lazy Interruption vs. Eager Interruption}\label{lazy-interruption}\noindent
In a system such as this, there is a language design choice that must be made---whether interruption is \emph{eager}, in which processes are interrupted immediately upon closing a channel, or \emph{lazy}, in which processes are only interrupted upon interaction with a closed channel. Both approaches have advantages and drawbacks. In making this choice, we desire that the behavior of interruption be \emph{predictable}---however, there are two competing viewpoints for predictability.

Consider the following example, with the assumption that \\ \verb/do-other-operation/ does not write to the standard output:
\begin{lstlisting}
( put 1 2 3; do-other-operation ) | take 3
\end{lstlisting}

\noindent
The left-hand side of the pipe will write three times, and then continue to do other processing in-thread that does not write to the standard output.
The final \verb/take 3/ operation will return after 3 inputs are read.
It is important to decide, then, whether the process on the left should be interrupted in the middle of \verb/do-other-operation/ (\emph{eager interruption}), or whether it should be left alone until it attempts to write a value (\emph{lazy interruption}).

From the perspective of someone spawning a process, eager interruption can seem more predictable, as they can guarantee a point at which the process has stopped doing work.

However, from the perspective of a function author, lazy interruption is more predictable, because the author can identify precisely which points in the code have the potential to be interrupted---those points which run a \verb/put/ or a \verb/get/. Contrast this with eager-interruption semantics, where any point in the code may be interrupted, introducing the need for users to either mark critical sections and be very careful with implementing stateful algorithms.

On the other hand, lazy interruption has the disadvantage that a producing process must do enough work to produce one more value than will be consumed. If each value is relatively cheap to produce, this is not a problem, but in the case that the values are expensive to produce, this would result in a large amount of unnecessary work.

% sensei comments:
% I see. Let's delete this paragraph, and improve the first sentence.

% The problem was, while Section 2 is supposed to list the requirements, Section 2.3.3 merely points out existence of two viewpoints. It made me feel like "well I understand that you see two viewpoints, then which one you require?"

% I think the requirement wrt eager/lazy interruption is that the language should support both interruption semantics and let the programmer use one of them selectively.
\subsubsection{Closing of Channels}\label{closing}\noindent
Given that multiple processes may be reading from and writing to a channel, it is often the case that a communicating process will end when there are other processes still communicating over the channel. It would not be appropriate in this case to interrupt other processes attached to the channel, as they are still able to communicate.

We define our guiding principle for the appropriate time to interrupt a process as: \emph{A process is interrupted exactly when it can no longer be woken up}.
When a process is blocked on a synchronous channel, it will be woken up as soon as another process communicates on the other end.
Therefore the appropriate time for it to be interrupted is when it is blocked on a channel that will never receive any more operations.

This can be difficult to detect when a reference to a channel can be passed anywhere in the program as a standard value. Luckily, the arrangement of pipes and channels are usually specified at process spawn time. We can therefore relax our constraint to guarantee that channels will be closed at appropriate times in \emph{common architectures}, and that they never close if there are active readers or writers.

\subsubsection{Reopening Channels}\label{closing-permanence}\noindent
Some systems, like UNIX named pipes, allow a channel to be re-used by new processes after it has been closed\cite{linux-pipe}. This is, however, not a desirable feature, as it can lead to some unexpected races between a channel closing and a new process spawning. Consider the example:
\begin{lstlisting}
c = (make-channel)     # create a new channel
& count-forever > $c   # write infinitely
& take 10 < $c         # read 10 elements and exit
put 10 > $c            # write once from a new process
\end{lstlisting}

\noindent
This example represents an unavoidable race with first-class channels: between \verb/take 10/ closing the channel and \verb/put 10/ opening the channel for writing. If we allow channel reopening, we will either block forever, or insert the number 10 into the stream, depending on which happens first. However if we do not allow channel reopening, we can say that, if a process initiates a read or write on a closed channel, it is immediately interrupted. In this case, both sides of the former race have the same termination behavior---the process is closed when \verb/take 10/ returns.

\subsubsection{Masking Interruptions}\label{masking}\noindent
We must include a facility to control the extend of interruptions. This is because an interruption semantics can make it difficult to perform final calculations after a channel is closed.

% A user will often wish to perform final calculations after a particular output channel has closed, and interruption semantics can make this difficult.
Consider the following example, which sums all numbers from the standard input:
% Consider the following example, which uses reservoir-sampling to select a uniform random element from a stream:
% \begin{lstlisting}
% (sample) = (
%   hold = (get)
%   i = 1
%   each (?v =>
%     $i = (inc $i)
%     # mutate with probability 1/$i
%     prob (recip $i) 1 && ($hold = %v)
%   )
% 
%   put $hold
% )
% \end{lstlisting}

% \noindent
% In this example, the function \verb/each/ will consume the entire input stream and mutate a variable with a given probability. After the entire input stream is consumed, we wish to output the resulting value stored in the \verb/$hold/ variable.
\begin{lstlisting}
(sum) = (
  total = 0
  each (?x => %total = (add %total %x))
  put %total
)
\end{lstlisting}\noindent
In this example, the function \verb/each/ will consume the input stream and mutate a lexical variable (marked with \verb/%/). After the entire input stream is consumed, we wish to output the resulting \verb/%total/ value.

However, with the semantics described above, the \verb/each/ function will loop until it receives an interrupt signal from the input channel closing, which will interrupt the entire process and not continue to the following line.

\section{Description of Magritte}\label{description}\noindent
We propose a language that meets the above requirements.

\subsection{Values and Variables}

\subsubsection{Lexical vs. Dynamic Variables}\noindent
In order to support both lexical and dynamic variables, we introduce a separate syntax for lexically scoped variables at variable reference and mutation points, using a \verb/%/ instead of \verb/$/ (for example, \verb/%x/). Let-binding is left unadorned (\verb/x = 1/), and will bind a variable both lexically and dynamically.

Let-binding uses this plain syntax to maintain compatibility with standard environment files. Variable binders in lambda arguments use \verb/?/ (e.g. \verb/?x/) to allow for unambiguous pattern matching, and are also bound both lexically and dynamically.


For mutation, we use assignment syntax, but with the location (dynamic or lexical) specified on the left-hand side, e.g. \verb/%x = 1/ or \verb/$x = 1/. In this way we avoid the need to declare variables, and allow ourselves to throw an exception when trying to mutate a non-existent variable, rather than silently creating a new local binding.

% In order to support both lexical and dynamic variables, we introduce a separate syntax for lexically scoped variables at the variable reference point, using a \verb/%/ instead of \verb/$/ (for example, \verb/%x/). Let-binding will bind a variable both lexically and dynamically, and uses an unadorned variable name (e.g. \verb/x = 1/), so that we can maintain compatibility with standard environment files. Variable binders in lambda arguments are similarly both lexical and dynamic, and use \verb/?/ (e.g. \verb/?x/) to allow for unambiguous pattern matching.

% For mutation, we use assignment syntax, but with the location (dynamic or lexical) specified on the left-hand side, e.g. \verb/%x = 1/ or \verb/$x = 1/. In this way we avoid the need to declare variables, and allow ourselves to throw an exception when trying to mutate a non-existent variable, rather than silently creating a new local binding.
\subsubsection{Lambda Functions}\noindent
Lambda functions are specified with parenthesized expressions containing the arrow symbol \verb/=>/, which separates the bindings from the body. Multiple matching clauses are possible, and can match simple patterns. Clauses are separated at the beginning of lines that contain \verb/=>/ (where "lines" are also terminated by \verb/;/, and do not consider nested newlines), which avoids the need for any indentation-based parsing. For example:
\begin{lstlisting}
my-function = (
  ?x =>
    put one-argument %x
  ?y ?z =>
    put two-arguments
    put %y %z
  ... => ...
)
\end{lstlisting}

\noindent
Named functions can also be defined using a parenthesized expression as the left hand side of an assignment:
\begin{lstlisting}
(my-function ?x ?y) = ...

# equivalent to
my-function = (?x ?y => ...)
\end{lstlisting}

\noindent
Functions maintain the scope of any free lexical variables in the body, including for mutation.

\subsubsection{Nestable Vectors}\noindent
We extend the concept of an \verb/argv/ vector such that it is nestable, using the compact syntax \verb/[ ]/. Combined with bareword strings (string literals without quotation), we can represent trees in a straightforward manner:
\begin{lstlisting}
a-tree = [node [node [leaf 1] [leaf 2]] [leaf 3]]
\end{lstlisting}
\noindent
These can be matched in lambda arguments by patterns such as \verb/[node ?x]/. A typical strategy for traversing this kind of structure might be a function that puts all leaf node values to its output in a predefined order, to be consumed by another process.

The builtin function \verb/for/ takes a vector as an argument and outputs each element in order, so that a vector can be traversed with:
\begin{lstlisting}
for [1 2 3 4 5] | each (?el => ...)
\end{lstlisting}

\subsubsection{Environments as Objects}\noindent
Variable environments can be captured directly as key-value maps with a parent pointer. Environment capture uses \verb/{ }/ syntax to run a block of code, then remove the running environment from its parent list. The resulting environment value is substituted in place of the \verb/{ }/ expression. Therefore all assignment syntaxes are available, including function definition. For example:
\begin{lstlisting}
(make-account ?balance) = {
 balance = $balance
 (deposit ?amt) = (%balance = (add %amt %balance))
 (withdraw ?amt) = (%balance = (sub %amt %balance))
}
\end{lstlisting}

\noindent
A planned extension would allow using special syntax to register additional parents, allowing users to inherit by direct delegation.

Environment lookup uses the \verb/!/ symbol, as in \verb/$env!key/. We use this symbol because it is already reserved by bash, unlike both \verb\/\ or \verb/./ which need to be available in bareword syntax to indicate file paths for external programs. Environments can also be mutated using the same access syntax. For example:
\begin{lstlisting}
account = (make-account 10)
$account!withdraw 4
put $account!balance # => 6
\end{lstlisting}

% \subsubsection{Reading and Writing}\noindent
% Reading and writing from the standard input and output are performed with the \verb/get/ and \verb/put/ functions, respectively. These block until they complete a communication.

\subsubsection{Collection and Substitution}\noindent
A priori, a capture mechanism such as described in Section \ref{return-semantics} would have to return a list, as any process may output zero or more values. However, as a function calling convention, that would require callers to manually unwrap lists on every function call.

In order to simplify substitution, Magritte uses normal parentheses to collect and \emph{expand} the resulting values into the current command vector---increasing the argument number by the number of values output from the function. For example:
\begin{lstlisting}
# A function defintion: output three values
(count-three) = (put 1; put 2; put 3)

# Collect three writes and expand 1 2 3 in-place
other-fn 0 (count-three) 4

# equivalent to
other-fn 0 1 2 3 4
\end{lstlisting}

\noindent
These semantics are similar to the \verb/$(...)/ syntax in bash, with the exception that we have the ability to properly separate values without relying on whitespace.

This mechanism is also available in vector literals, allowing us to collect outputs as a vector:
\begin{lstlisting}
outputs = [(some-command)]
\end{lstlisting}
\noindent
The \verb/list/ built-in function, which simply returns its argument vector, is also available for this purpose.
The \verb/for/ function mentioned above can be used to splat vector arguments into function calls:
\begin{lstlisting}
some-fn $arg1 $arg2 (for [$arg3 $arg4])
\end{lstlisting}

\subsubsection{Blocks}\noindent
A parenthesized grouping that is \emph{not} in argument position is a \emph{block}. Blocks do not collect or modify the environment's channels in any way, but instead simply run the code contained within them, and output values normally. These are mostly used to group commands within a pipeline, and in the body of function definitions:
\begin{lstlisting}
generate-values | (process; process; process)
\end{lstlisting}
\noindent
In the case that a user might want to use a substitution at the root level---i.e. to generate a function and immediately call it, we provide the \verb/exec/ builtin which executes its arguments as a command.

\subsection{Channels and Processes}
\subsubsection{Synchronous Channels}\noindent
Channels in Magritte are \emph{synchronous}---readers and writers cannot continue until a communication is completed successfully. Given the decision to allow rich values to be passed through channels, we have decided that a buffer is not as necessary for performance purposes, since a single write may contain an arbitrarily large amount of data---or for that matter a process handle or object reference. Additionally, synchronous channels have simpler semantics both for implementation and for users, and we leave open the possibility of user-implemented queues, such as:
\begin{lstlisting}
producer | buffer 10 | consumer
\end{lstlisting}

\subsubsection{Spawning and Redirecting}\noindent
Spawning uses an ampersand (\verb/&/), similar to bash, at the \emph{beginning} of a command indicating that it should be spawned in a new thread.

Standard input and output may be redirected into and from channels using the \verb/>/ and \verb/</ symbols, or chained together with the pipe (\verb/|/) symbol, much like \verb/bash/. Commands in pipelines will all be spawned in their own threads, with the exception of the final command, which will be run in the current process.

\subsection{Interruption and Compensation}

\subsubsection{Lazy Interruption}\noindent
We have decided that the predictability of lazy interruption is worth the tradeoff for the extra-values problem discussed in Section \ref{lazy-interruption}, and we discuss some ways to mitigate this problem in Section \ref{discussion}.

\subsubsection{Process Registration}\label{process-registration}
In order to satisfy the constraints of Section \ref{closing}, we maintain a process register inside of each channel, so that we can decide when all readers or all writers have returned or been interrupted, at which time we can guarantee that processes on the other side of the channel cannot be woken up \emph{without spawning new processes}. Therefore this covers the architecture of pipelines, in which many processes are spawned together in fixed configurations. Other architectures will have to manually manage process shutdown in some cases.

\subsubsection{Compensation and Unconditional Compensation}\noindent
 We employ a variant of the compensation mechanism introduced by Inoue et al.\cite{compensation}
using the \verb/%%/ operator to indicate a compensation action, which is run in case of an interruption in the left hand side or subsequent lines. Compensations are cleared at the end of the current function body:
\begin{lstlisting}
(my-function) = (
  action %% cleanup-action
  # in effect until the end of the function
)
\end{lstlisting}

\noindent Additionally, we define \emph{unconditional compensations} using the \verb/%%!/ operator, which run both in the case of an interruption and in the case of a normal return. In this way, they are analogous to \verb/finally/ or \verb/ensure/ sections of standard exception handling.
For example, the function \verb/read-lines/ above could be implemented as:
\begin{lstlisting}
(read-lines ?fname) =
 (f = (open-file $fname) %%! close-file $fname
  until (=> eof? $f) (=> read-until "\n" $f))
\end{lstlisting}

\noindent
In this way, we can ensure that the file is closed when the function exits, whether by a normal return or by interruption.

\subsubsection{Interrupt Handling}\noindent
While we plan to explore more general mechanisms for exception handling, we find that it suffices for most applications to provide two builtin functions, \verb/produce/ and \verb/consume/, to indicate the intent to fill or consume the entirety of the output or input streams, respectively. Each of these functions takes a single zero-argument function which will loop forever until the standard output or standard input respectively is closed, whereby control flow continues after the invocation. Using these functions, we might define \verb/each/ as:
\begin{lstlisting}
(each ?fn) = (consume (=> %fn (get)))
\end{lstlisting}

\noindent
With this definition, the call to \verb/consume/ will mask the interruption from the standard input closing, and control flow after any \verb/each/ invocation will continue as normal. This is enough to resolve the issue discussed in Section \ref{masking}.

\section{Implementation of Magritte}\label{implementation}

\noindent
The current version of Magritte is implemented as a straightforward interpreter written in Ruby, using Ruby's builtin threads, exceptions, and mutexes to implement processes and channels.

\subsection{Channel Registry}\noindent
Our channel implementation is a standard implementation of synchronous channels, with the addition of four intrinsic methods, used only internally by the interpreter: \verb/add_reader/, \verb/remove_reader/, \verb/add_writer/, and \verb/remove_writer/, which register and deregister processes as described in Section \ref{process-registration}. When a \verb/remove_*/ method results in an empty set, it will additionally close the channel and raise an internal exception in every blocked thread.

Once the channel is closed, every call to \verb/read/ and \verb/write/ will interrupt the calling process as described in Section \ref{closing-permanence}.

In order to reduce unnecessary use of Ruby threads, we also find it is simpler, instead of registering \emph{processes} to the channels, to register \emph{stack frames}. In this way, we can register all inputs and outputs on frame entry, and use standard Ruby exception handling to ensure we properly run compensations and deregister inputs and outputs on frame exit. This means that different frames in the same process can be connected to different channels, which makes the \verb/>/ and \verb/</ redirection syntax straightforward to implement---we simply push a new frame with different channels attached.

Interruptions then cascade naturally---when a channel closes, a process is interrupted, causing it to unwind its stack and deregister channels, thereby potentially causing other channels to close.

\subsection{Spawning Order Dependency}\noindent
It is necessary to take some care with the implementation of the spawning primitive (\verb/&/), that we wait until the spawned process has finished registering its channels before the spawning process continues. % For this reason the root frame of a process always has its channels registered by the \emph{spawning} process before it is allowed to start.
Consider the following example, which outputs 10 numbers, possibly out of order:
\begin{lstlisting}
(drain) = (each (?x => put %x))
count-forever | (& drain; & drain) | take 10
\end{lstlisting}
\noindent
The middle process is responsible for spawning two processes that funnel data from their input to their output. However, since they are both spawned in the background, the spawning process will immediately return. In general, the \verb/drain/ processes should be keeping the two pipes open. However, if we do not take care to wait until they have finished registering their channels, there is a risk that the spawning process will return first and close the two pipes.

\subsection{Collectors}\noindent
In order to implement the return semantics described in Section \ref{return-semantics}, we also implement a write-only channel called a \emph{collector}, and an intrinsic that waits for channel closing. Collectors cannot be created directly by users, but only appear in the interpreter when we evaluate parentheses in argument position.

Naively, collectors would ignore registration commands and simply append written elements to an array. However, it is still necessary to track registered writers. Consider the example:
\begin{lstlisting}
(range ?n) = (count-forever | take %n)
my-list = [(range 10 | (& drain; & drain))]
\end{lstlisting}

\noindent
In this example, there is an open question of how long we should wait until reading the collection and continuing. If we naively wait until the base command is finished, we will continue early and miss values that may be written later. Thus substitution waits until all writers to the collector have deregistered.

To implement this, we add a \verb/wait_for_close/ intrinsic to collectors, which returns immediately if closed, and otherwise adds the current thread to a waiting set and sleeps. Upon closing the channel, all elements of this waiting set are awoken, and flow continues. Thus the algorithm for substituting a block is:
\begin{lstlisting}[language={}]
* Create a new collector $c
* Run the parenthesized expressions with standard output set to the collector
* Run $c.wait_for_close
\end{lstlisting}

\noindent
In the most common case, there will only be a single thread writing to the collector, so that the channel will be closed by the time the evaluation is finished, making \verb/wait_for_close/ a null operation.

\section{Discussion}\label{discussion}

\subsection{Open Checking}\noindent
Because our system implements \emph{lazy interruption}, we must mitigate the problem of producers creating one extra element than is needed, in the case that elements are expensive to produce. One possibility is to introduce the concept of \emph{open checking}, so that producer processes can periodically run a builtin command that will interrupt if the output is closed, without actually writing any data to the channel.

% \subsection{Pattern Matching}\noindent
% Though the syntax design is not yet complete, we plan to allow pattern matching in all lambda bindings. In order to potentially support glob and regular expression matching, we must be careful which symbols we reserve in this context.

% \subsection{Prototypical Inheritance}\noindent
% One missing feature to support prototypical inheritance is the dynamic assignment of a special \verb/$self/ variable. We plan to implement a system similar to JavaScript, in that the \verb/$self/ variable is assigned dynamically based on the calling syntax, or overrideable with special-purpose functions.

\subsection{OS Integration}\noindent
In order to be viable as a shell, we must integrate seamlessly with a POSIX-like environment. This involves marshalling values to strings and byte streams in order to communicate with external processes, and allowing external processes to interact with Magritte values. We plan to use a suite of parsing and unparsing functions for linewise and table data, along with a custom JSON streaming format to allow integration with most languages. We also plan to use a socket and a static executable to allow external programs to call back into Magritte lambda functions.

\ifsigpro{
\subsection{Macros}\noindent
While we do not currently have a use case for macros, it is likely that there is a use case for syntactic abstraction. Our parsing technique involves an intermediate \emph{skeleton tree} representation adapted from Bachrach and Playford\cite{skeleton-trees} that makes macro systems simpler to implement in non-lisp syntaxes.
}

\subsection{Performance}\noindent
The current Ruby interpreter is slow. We plan to bootstrap using a JIT-compiled virtual machine implemented in RPython.

\subsection{Desktop Scripting}\noindent
We believe Magritte offers a promising solution to the \emph{desktop scripting problem}: an interface for end users to integrate and automate independent programs, a problem attempted by projects such as Guile Scheme\cite{guile} and TCL\cite{tcl}.
What differentiates our approach is that our platform should be able to integrate with programs as they are currently written, without the need for further integration on the part of application developers.

\section{Related Work}\label{related-work}

% * pipe objects
% * lightweight syntax
% * data structures

% \subsection{Iterators}
% \noindent
% Many general purpose languages such as Python implement an iterator API, for code that is intended to produce values in a streamlike fashion. For example, in a Python Enhancement Proposal (PEP), Smith\cite{pep533} describes an automatic closing system for generators, in which an \verb/__iterclose__/ signal is sent by the consumer back to the producer as soon as a consumer exits early.

% But channel-based systems generally allow for multiple concurrent readers and writers---so automatically cleaning up a channel when a single consumer exits would cause processes that are still able to communicate to be terminated early.

\subsection{General-Purpose Languages}

\noindent
Many general purpose languages, including Go\cite{golang} and Clojure\cite{clojure}, contain robust channel implementations, which can be used to implement a variety of concurrent algorithms. In such a system we could implement something similar to our system by adding input and output channels to every function and heavily currying functions.

% For example, in an untyped language similar to Go (the following implementation is not possible in general in Go without generic types), we could implement something similar to our system by adding input and output channels to every function and heavily currying functions:
% \begin{lstlisting}[language=C, morekeywords={fn,channel,nil,go}]
% fn pipe(lhs, rhs, inp, out) {
%   c = channel()
%   go fn () { lhs(inp, c); };
%   rhs(c, out)
% }
% 
% collect = collector()
% pipe(curry(range, 10), curry(fan, 2, fn(el, inp, out) { write(el + 1, out); }), nil, collect);
% 
% return collect.values()
% \end{lstlisting}
% \noindent
However, such a system would still require manual use of input and output channels when a simple pipeline would suffice---and the user must still translate between returning vs. outputting functions and expressions. Additionally, these systems do not contain any kind of channel closing semantics or automatic process cleanup. % Finally, such a system would be far too heavyweight for a REPL context, and would not make for a viable interactive shell.

\subsection{Shell Extensions} \noindent
Many systems, such as \verb/xonsh/\cite{xonsh} and Es Shell\cite{haahr}, attempt to extend traditional shells with object or functional semantics, but do not sufficiently integrate their semantics with pipes, leaving pipes to remain bytes-only.

Systems that extend existing languages with shell semantics, such as \verb/scheme-shell/, also do not integrate fully with pipes.

% Projects such as \verb/xonsh/\cite{xonsh} and \verb/scheme-shell/\cite{scheme-shell} attempt to extend the syntax of an existing general purpose language to include shell capabilities. Unfortunately, this approach creates a schism between shell concepts and host language concepts---in particular, host language objects cannot be passed through pipes.

% The \verb/es/ shell \cite{haahr}, which is an extension of the \verb/rc/ shell \cite{duff} from the Plan 9 operating system, attempts to extend the standard shell model with lambda functions with lexical scoping. These shell functions are marshalled into strings when passed through pipes (whether to shell functions or external programs), but are still written byte-by-byte and thus are subject to interleaving in concurrent cases.

\subsection{Object Shells}\noindent
Projects such as \verb/powershell/\cite{powershell} and \verb/mash/\cite{mash} allow objects (.NET objects and Scala objects, respectively) to be passed through pipelines. However, this approach still ties the language to one specific platform or object system and makes it difficult to integrate with programs written for other platforms. By \emph{only} relying on the most universal OS concepts of standard input/output, argument vectors, and interrupt signals, we should be able to integrate programs across a wide variety of languages and platforms.

% Like the Es shell, we also wish to provide lambda functions with lexically scoped variables. However, Es has an ambiguity with respect to its variables---since both lexically scoped variables and dynamically scoped variables share the same syntax, the scope of a variable depends on which variables happen to be bound in the function's definition environment. Therefore a simple mistype of a variable name will result not in an error, but in the variable silently becoming dynamically bound.

\subsection{PUSH Shell}\noindent
The PUSH shell\cite{push} extends a traditional shell with \emph{fan-out} and \emph{fan-in} operators which separate data into discrete records. This enables it to be used safely to orchestrate distributed computing tasks. However, the underlying pipe implementation remains byte-based, so that features like Magritte's collection and expansion remain impossible.

\section{Conclusion}\label{conclusion} \noindent
We proposed Magritte, which is both capable of integrating closely with operating systems, and serving as a general-purpose language for larger applications.  Our channel implementation allows for robust composition of concurrent algorithms, and can also serve as the fundamental unit of composition for our language, which integrates with modern general-purpose language features like rich data structures and lambda functionsn with lexical scoping.

At the same time, the language stays close enough to the common OS spawning model that we believe it should be straightforward to integrate with an operating system. Because of this, we believe Magritte is capable of filling a currently unserved niche as a desktop integration language, and also provides an interesting platform for experimenting and building concurrent algorithms.

% hack: acmart apparently requires acks to be verbatim in the file,
% so we alias acks -> acknowledgement for the ipsj template
\ifsigpro{
\newenvironment{acks}{\begin{acknowledgment}}{%
\end{acknowledgment}\ignorespacesafterend
}
}

\begin{acks}
This work was supported by JSPS KAKENHI Grant Number 18H03219.  J. Westlund's contribution to this research was made possible by
  %funding from
The Sweden-Japan Foundation and Stockholms Grosshandelssocietet.
\end{acks}

\ifsigpro{\bibliographystyle{ipsjsort-e}}
\ifsigplan{\bibliographystyle{ACM-Reference-Format}}
\bibliography{paper}

\end{document}

